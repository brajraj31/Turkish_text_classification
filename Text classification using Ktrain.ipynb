{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('turkish_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   category                                               text\n",
       "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
       "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>siyaset</td>\n      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>siyaset</td>\n      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of records present in dataset: 4900\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records present in dataset: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Dataset consist of news with different category like 'dunya'(word), siyaset(Politics), ekonomi(economics) etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total different category in Datatset:\n['siyaset ' 'dunya ' 'ekonomi ' 'kultur ' 'saglik ' 'spor ' 'teknoloji ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total different category in Datatset:\")\n",
    "print(df['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment belwo line to install ktrain \n",
    "#!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package words to /home/ubuntu/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import required packaged\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_cleaning(df_data):\n",
    "    \"\"\"This function helps to remove row with missing value or if there is any dupicate records\"\"\"\n",
    "    df_data = df_data.dropna()\n",
    "    df_data = df_data.drop_duplicates()\n",
    "    df_data = df_data.reset_index(drop=True)\n",
    "    return df_data\n",
    "\n",
    "def text_cleaning(text):\n",
    "    \"\"\"This function helps to clean a text after removing stop words, short words, special character,\n",
    "    any link present and use stemmer to provide near to root word\"\"\"\n",
    "    stop = set(stopwords.words(\"turkish\"))\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^abcçdefgğhıijklmnoöprsştuüvyzmi̇z]',' ', text)\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split() if (word not in stop) and len(word)>1])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4540, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are taking only 25 percent of data from whole dataset to fine tune our model with less time.\n",
    "dataset = dataset.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      category                                               text  \\\n",
       "1295    dunya    türkiye_nato dan patriot talebinde bulunmadı ...   \n",
       "1627  ekonomi    internet bankacılığı kullananlar dikkat ! ist...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "1295  türki nato dan patriot talep bulun nato genel ...  \n",
       "1627  internet bankacılık kullanan dikkat istanbul b...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1295</th>\n      <td>dunya</td>\n      <td>türkiye_nato dan patriot talebinde bulunmadı ...</td>\n      <td>türki nato dan patriot talep bulun nato genel ...</td>\n    </tr>\n    <tr>\n      <th>1627</th>\n      <td>ekonomi</td>\n      <td>internet bankacılığı kullananlar dikkat ! ist...</td>\n      <td>internet bankacılık kullanan dikkat istanbul b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "dataset['cleaned_text'] = dataset['text'].apply(lambda x:text_cleaning(x))\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(dataset['cleaned_text']), np.array(dataset['category']),\n",
    "                                                   test_size = 0.20, random_state=42, stratify = dataset['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electra model ref: https://huggingface.co/dbmdz/electra-base-turkish-cased-discriminator\n",
    "i am going to use ELECTRA instead of BERT as it peformed beter with high GLEU score in different research. Electra perfomance is better when you have computing resource limitation. It takes less training time comparing to BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preprocessing train...\n",
      "language: tr\n",
      "train sequence lengths:\n",
      "\tmean : 233\n",
      "\t95percentile : 572\n",
      "\t99percentile : 848\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is Multi-Label? False\npreprocessing test...\nlanguage: tr\ntest sequence lengths:\n\tmean : 257\n\t95percentile : 633\n\t99percentile : 1009\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = 'dbmdz/electra-base-turkish-cased-discriminator'\n",
    "t= text.Transformer(MODEL_NAME, maxlen=500, classes= dataset['category'].unique())\n",
    "train = t.preprocess_train(X_train, y_train)\n",
    "val = t.preprocess_test(X_test, y_test)\n",
    "model = t.get_classifier()\n",
    "leaner = ktrain.get_learner(model, train_data = train, val_data = val, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaner.lr_find() #to find good leaning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 3925s 85s/step - loss: 1.9401 - accuracy: 0.1537 - val_loss: 1.7807 - val_accuracy: 0.4934\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 3899s 85s/step - loss: 1.4998 - accuracy: 0.6156 - val_loss: 0.6783 - val_accuracy: 0.8546\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 3894s 85s/step - loss: 0.5661 - accuracy: 0.9055 - val_loss: 0.5639 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b11551290>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "leaner.fit_onecycle(5e-5, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(leaner.model, preproc=t)\n",
    "predictor.save(\"./ktrain/electra_text_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take a sample news\n",
    "news_text = dataset['cleaned_text'].iloc[10]\n",
    "actual_category = dataset['category'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Actual category is spor \n"
     ]
    }
   ],
   "source": [
    "print(f\"Actual category is {actual_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicted category is spor \n"
     ]
    }
   ],
   "source": [
    "print(f\"predicted category is {predictor.predict(dataset['cleaned_text'].iloc[10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload saved model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'spor '"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "reloaded_predictor = ktrain.load_predictor('./ktrain/electra_text_classifier')\n",
    "reloaded_predictor.predict(dataset['cleaned_text'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confidence score: 0.8901882767677307\n"
     ]
    }
   ],
   "source": [
    "print(f\"confidence score: {np.max(reloaded_predictor.predict_proba(dataset['cleaned_text'].iloc[10]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dl_vf",
   "language": "python",
   "name": "venv_dl_vf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}